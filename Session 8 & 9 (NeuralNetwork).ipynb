{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralNetwork.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YasaminRhd/Pythonia.init/blob/main/Session%208%20%26%209%20(NeuralNetwork)\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct26F2J_g3N8"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "from sklearn import preprocessing\n",
        "#np.set_printoptions(threshold=sys.maxsize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PxfchVMHkOpL",
        "outputId": "d3274e6c-7d47-4630-c1a0-b0b81984ab5e"
      },
      "source": [
        "dataset = pd.read_csv('bp1.csv')\n",
        "x = dataset.iloc[:,3:-1].values\n",
        "y = dataset.iloc[:,-1].values\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
              "1          2    15647311      Hill  ...               1       112542.58      0\n",
              "2          3    15619304      Onio  ...               0       113931.57      1\n",
              "3          4    15701354      Boni  ...               0        93826.63      0\n",
              "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z10r6v3VCZQl",
        "outputId": "4fd3ae7c-a49f-433e-9fe5-40b3f819ea82"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, ..., 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o36sUx30sZzA",
        "outputId": "a7311777-60e5-4a40-9608-234d253adced"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[619, 'France', 'Female', ..., 1, 1, 101348.88],\n",
              "       [608, 'Spain', 'Female', ..., 0, 1, 112542.58],\n",
              "       [502, 'France', 'Female', ..., 1, 0, 113931.57],\n",
              "       ...,\n",
              "       [709, 'France', 'Female', ..., 0, 1, 42085.58],\n",
              "       [772, 'Germany', 'Male', ..., 1, 0, 92888.52],\n",
              "       [792, 'France', 'Female', ..., 1, 0, 38190.78]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLEFrGHLO0wr"
      },
      "source": [
        "#Data imputation and correction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz9CHYcPN91q"
      },
      "source": [
        "# from sklearn.impute import SimpleImputer\n",
        "# imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
        "# imp = imp.fit(x[:,:])\n",
        "# x[:,:] = imp.transform(x[:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JkNUWUEO3_d"
      },
      "source": [
        "#Encoding strings and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s26k4CdOAjL"
      },
      "source": [
        "# from sklearn.preprocessing import OrdinalEncoder\n",
        "# enc = OrdinalEncoder()\n",
        "# enc = enc.fit(x[:,1])\n",
        "# x[:,1] = enc.transform(x[:,1])\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le_country = LabelEncoder()\n",
        "x[:,1] = le_country.fit_transform(x[:,1])\n",
        "le_gender = LabelEncoder()\n",
        "x[:,2] = le_gender.fit_transform(x[:,2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQipcpD6PzjQ"
      },
      "source": [
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# le_country2 = LabelEncoder()\n",
        "# le_country2 = le_country2.fit(x[:,0])\n",
        "# x[:,0] = le_country2.transform(x[:,0])\n",
        "# le_y = LabelEncoder()\n",
        "# y = le_y.fit_transform(y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f9IJ3uZPOMA"
      },
      "source": [
        "#Neutralizing weight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBQlKM8ZONs3",
        "outputId": "46b3bf5b-db6e-4c83-f66d-07907ab6ca72"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "ct = ColumnTransformer([(\"country\", OneHotEncoder(), [1])], remainder='passthrough')\n",
        "x = ct.fit_transform(x)\n",
        "x = x[:,1:]\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0, 0.0, 619, ..., 1, 1, 101348.88],\n",
              "       [0.0, 1.0, 608, ..., 0, 1, 112542.58],\n",
              "       [0.0, 0.0, 502, ..., 1, 0, 113931.57],\n",
              "       ...,\n",
              "       [0.0, 0.0, 709, ..., 0, 1, 42085.58],\n",
              "       [1.0, 0.0, 772, ..., 1, 0, 92888.52],\n",
              "       [0.0, 0.0, 792, ..., 1, 0, 38190.78]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8xqmq2QPP7d"
      },
      "source": [
        "#Splitting train and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eux3dfSpOSjR",
        "outputId": "ca7d6fdd-89b1-4944-b7b0-9089f954310d"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)\n",
        "x_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0, 0.0, 571, ..., 1, 0, 28045.77],\n",
              "       [0.0, 0.0, 704, ..., 0, 1, 66810.48],\n",
              "       [0.0, 1.0, 772, ..., 1, 1, 75825.57],\n",
              "       ...,\n",
              "       [0.0, 1.0, 560, ..., 0, 0, 128882.66],\n",
              "       [1.0, 0.0, 547, ..., 1, 0, 67789.99],\n",
              "       [0.0, 0.0, 797, ..., 0, 0, 125110.02]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w_qfcQjPW_3"
      },
      "source": [
        "#Scaling the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Eu9PcWCOVGI",
        "outputId": "d5b65d71-cc95-4745-abfa-b84bce4ce43f"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_x = StandardScaler()\n",
        "x_train = sc_x.fit_transform(x_train)\n",
        "x_test = sc_x.fit_transform(x_test)\n",
        "x_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.73436329, -0.56657212,  0.31446453, ..., -1.55901627,\n",
              "        -1.03771056, -0.82141368],\n",
              "       [-0.57658047, -0.56657212,  0.39678644, ...,  0.64143012,\n",
              "        -1.03771056, -0.679803  ],\n",
              "       [ 1.73436329, -0.56657212,  1.08623239, ..., -1.55901627,\n",
              "        -1.03771056, -0.96381456],\n",
              "       ...,\n",
              "       [-0.57658047, -0.56657212,  0.01604763, ...,  0.64143012,\n",
              "         0.96365985,  0.94804517],\n",
              "       [-0.57658047, -0.56657212, -0.45730333, ..., -1.55901627,\n",
              "         0.96365985,  0.53289563],\n",
              "       [-0.57658047,  1.76500038, -0.95123476, ...,  0.64143012,\n",
              "        -1.03771056, -0.76603013]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Frdk_IpHOXwM"
      },
      "source": [
        "# from sklearn.preprocessing import Normalizer\n",
        "# norm = Normalizer()\n",
        "# x_test = norm.fit_transform(x_test)\n",
        "# x_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1deVNV8OaBG"
      },
      "source": [
        "# from sklearn.preprocessing import normalize\n",
        "# norm2 = normalize(x_test)\n",
        "# norm2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3O6Z7lDEA0M",
        "outputId": "25bf77f9-7296-419b-9fb6-3f7549217c2e"
      },
      "source": [
        "#X_train length is used for explaning the difinition of batch and epoch in the article\n",
        "print(len(x_train))\n",
        "print(len(x_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8000\n",
            "2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix2hXMtAE-3D"
      },
      "source": [
        "#9th Session\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NqlDJdNE-fN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f638717a-9ef8-4d57-da66-1f8a2f1826e6"
      },
      "source": [
        "#explained example\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "#neural network skeleton\n",
        "classifier = Sequential()\n",
        "\n",
        "#hidden layer 1 - input from input data\n",
        "classifier.add(Dense(input_shape=(11,), units=6, kernel_initializer='random_uniform', activation='relu'))\n",
        "\n",
        "#hidden layer 2\n",
        "classifier.add(Dense(units=10, kernel_initializer='random_uniform', activation='relu'))\n",
        "\n",
        "#Binary output layer \n",
        "classifier.add(Dense(units=1, kernel_initializer='random_uniform', activation='sigmoid'))\n",
        "\n",
        "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "classifier.fit(x_train, y_train, batch_size=10, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "800/800 [==============================] - 14s 1ms/step - loss: 0.5497 - accuracy: 0.7875\n",
            "Epoch 2/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4345 - accuracy: 0.7912\n",
            "Epoch 3/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4197 - accuracy: 0.8073\n",
            "Epoch 4/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4192 - accuracy: 0.8226\n",
            "Epoch 5/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4212 - accuracy: 0.8276\n",
            "Epoch 6/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4197 - accuracy: 0.8263\n",
            "Epoch 7/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4190 - accuracy: 0.8276\n",
            "Epoch 8/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4116 - accuracy: 0.8306\n",
            "Epoch 9/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4221 - accuracy: 0.8246\n",
            "Epoch 10/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4235 - accuracy: 0.8270\n",
            "Epoch 11/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4032 - accuracy: 0.8369\n",
            "Epoch 12/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4068 - accuracy: 0.8331\n",
            "Epoch 13/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4193 - accuracy: 0.8292\n",
            "Epoch 14/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4037 - accuracy: 0.8367\n",
            "Epoch 15/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4139 - accuracy: 0.8300\n",
            "Epoch 16/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4090 - accuracy: 0.8351\n",
            "Epoch 17/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3974 - accuracy: 0.8439\n",
            "Epoch 18/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4001 - accuracy: 0.8394\n",
            "Epoch 19/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4093 - accuracy: 0.8320\n",
            "Epoch 20/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4143 - accuracy: 0.8255\n",
            "Epoch 21/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4057 - accuracy: 0.8385\n",
            "Epoch 22/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4082 - accuracy: 0.8335\n",
            "Epoch 23/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4093 - accuracy: 0.8278\n",
            "Epoch 24/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4033 - accuracy: 0.8380\n",
            "Epoch 25/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4008 - accuracy: 0.8370\n",
            "Epoch 26/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4040 - accuracy: 0.8383\n",
            "Epoch 27/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4162 - accuracy: 0.8258\n",
            "Epoch 28/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4008 - accuracy: 0.8367\n",
            "Epoch 29/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4058 - accuracy: 0.8373\n",
            "Epoch 30/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4129 - accuracy: 0.8318\n",
            "Epoch 31/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3965 - accuracy: 0.8409\n",
            "Epoch 32/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4118 - accuracy: 0.8329\n",
            "Epoch 33/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3983 - accuracy: 0.8338\n",
            "Epoch 34/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4063 - accuracy: 0.8357\n",
            "Epoch 35/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3963 - accuracy: 0.8404\n",
            "Epoch 36/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4198 - accuracy: 0.8259\n",
            "Epoch 37/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4047 - accuracy: 0.8317\n",
            "Epoch 38/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4074 - accuracy: 0.8285\n",
            "Epoch 39/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4024 - accuracy: 0.8392\n",
            "Epoch 40/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3996 - accuracy: 0.8391\n",
            "Epoch 41/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4075 - accuracy: 0.8323\n",
            "Epoch 42/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4003 - accuracy: 0.8359\n",
            "Epoch 43/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4035 - accuracy: 0.8350\n",
            "Epoch 44/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4087 - accuracy: 0.8351\n",
            "Epoch 45/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3946 - accuracy: 0.8387\n",
            "Epoch 46/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3922 - accuracy: 0.8430\n",
            "Epoch 47/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3983 - accuracy: 0.8364\n",
            "Epoch 48/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3804 - accuracy: 0.8436\n",
            "Epoch 49/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4150 - accuracy: 0.8281\n",
            "Epoch 50/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4121 - accuracy: 0.8317\n",
            "Epoch 51/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4033 - accuracy: 0.8340\n",
            "Epoch 52/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4096 - accuracy: 0.8318\n",
            "Epoch 53/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4070 - accuracy: 0.8279\n",
            "Epoch 54/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4043 - accuracy: 0.8327\n",
            "Epoch 55/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3928 - accuracy: 0.8393\n",
            "Epoch 56/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4114 - accuracy: 0.8307\n",
            "Epoch 57/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3930 - accuracy: 0.8387\n",
            "Epoch 58/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4091 - accuracy: 0.8339\n",
            "Epoch 59/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3943 - accuracy: 0.8411\n",
            "Epoch 60/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3997 - accuracy: 0.8321\n",
            "Epoch 61/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4047 - accuracy: 0.8302\n",
            "Epoch 62/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4073 - accuracy: 0.8301\n",
            "Epoch 63/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3953 - accuracy: 0.8396\n",
            "Epoch 64/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4101 - accuracy: 0.8338\n",
            "Epoch 65/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4031 - accuracy: 0.8350\n",
            "Epoch 66/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3950 - accuracy: 0.8383\n",
            "Epoch 67/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3871 - accuracy: 0.8439\n",
            "Epoch 68/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3901 - accuracy: 0.8438\n",
            "Epoch 69/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4009 - accuracy: 0.8360\n",
            "Epoch 70/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4034 - accuracy: 0.8345\n",
            "Epoch 71/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4061 - accuracy: 0.8334\n",
            "Epoch 72/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4062 - accuracy: 0.8289\n",
            "Epoch 73/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3947 - accuracy: 0.8407\n",
            "Epoch 74/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4133 - accuracy: 0.8291\n",
            "Epoch 75/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3974 - accuracy: 0.8384\n",
            "Epoch 76/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3965 - accuracy: 0.8342\n",
            "Epoch 77/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4033 - accuracy: 0.8354\n",
            "Epoch 78/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4036 - accuracy: 0.8321\n",
            "Epoch 79/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4061 - accuracy: 0.8320\n",
            "Epoch 80/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3993 - accuracy: 0.8358\n",
            "Epoch 81/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4101 - accuracy: 0.8305\n",
            "Epoch 82/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4228 - accuracy: 0.8228\n",
            "Epoch 83/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4064 - accuracy: 0.8297\n",
            "Epoch 84/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4144 - accuracy: 0.8300\n",
            "Epoch 85/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4021 - accuracy: 0.8353\n",
            "Epoch 86/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3965 - accuracy: 0.8407\n",
            "Epoch 87/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4063 - accuracy: 0.8344\n",
            "Epoch 88/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4053 - accuracy: 0.8356\n",
            "Epoch 89/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3985 - accuracy: 0.8393\n",
            "Epoch 90/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4032 - accuracy: 0.8371\n",
            "Epoch 91/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4053 - accuracy: 0.8334\n",
            "Epoch 92/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4139 - accuracy: 0.8306\n",
            "Epoch 93/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3934 - accuracy: 0.8413\n",
            "Epoch 94/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3998 - accuracy: 0.8369\n",
            "Epoch 95/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3984 - accuracy: 0.8384\n",
            "Epoch 96/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3958 - accuracy: 0.8366\n",
            "Epoch 97/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.4046 - accuracy: 0.8353\n",
            "Epoch 98/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3956 - accuracy: 0.8399\n",
            "Epoch 99/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3941 - accuracy: 0.8412\n",
            "Epoch 100/100\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 0.3977 - accuracy: 0.8386\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7feba92ee610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IICAqcEqEy3t"
      },
      "source": [
        "#First Try"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nxGyUtTjl4UI",
        "outputId": "0968ce9e-d695-4c92-d024-a7aa5aa5c007"
      },
      "source": [
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "!rm -rf ./logs/\n",
        "\n",
        "%reload_ext tensorboard\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "#Create Sequential model with Dense layers\n",
        "classifier = Sequential()\n",
        "\n",
        "#hidden layer 1 - input from input data\n",
        "classifier.add(Dense(input_shape=(11,), units=7, kernel_initializer='random_uniform', activation='relu'))\n",
        "\n",
        "#hidden layer 2\n",
        "classifier.add(Dense(units=9, kernel_initializer='random_uniform', activation='relu'))\n",
        "\n",
        "#Binary output layer \n",
        "classifier.add(Dense(units=1, kernel_initializer='random_uniform', activation='sigmoid'))\n",
        "\n",
        "#The compile method configures the model’s learning process\n",
        "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "log_dir = \"logs/firstTry/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "#The fit method does the training in batches\n",
        "classifier.fit(x_train, y_train, batch_size=5, epochs=150, validation_data=(x_test, y_test), callbacks=[tensorboard_callback])\n",
        "\n",
        "%tensorboard --logdir logs/firstTry"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mThis cell output is too large and can only be displayed while logged in.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5ZpcsaFE6UK"
      },
      "source": [
        "#Second Try"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WNkti7trE58X",
        "outputId": "b8d9bbd8-6afa-4b26-a876-1e1e60c7d044"
      },
      "source": [
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "%reload_ext tensorboard\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "#Create Sequential model with Dense layers\n",
        "classifier = Sequential()\n",
        "\n",
        "#hidden layer 1 - input from input data\n",
        "classifier.add(Dense(input_shape=(11,), units=8, kernel_initializer='random_uniform', activation='relu'))\n",
        "\n",
        "#hidden layer 2\n",
        "classifier.add(Dense(units=10, kernel_initializer='random_uniform', activation='relu'))\n",
        "\n",
        "#Binary output layer \n",
        "classifier.add(Dense(units=1, kernel_initializer='random_uniform', activation='sigmoid'))\n",
        "\n",
        "#The compile method configures the model’s learning process\n",
        "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "log_dir = \"logs/secondTry/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "#The fit method does the training in batches\n",
        "classifier.fit(x_train, y_train, batch_size=20, epochs=200, validation_data=(x_test, y_test), callbacks=[tensorboard_callback])\n",
        "\n",
        "%tensorboard --logdir logs/secondTry"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mThis cell output is too large and can only be displayed while logged in.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34V23QsLE9TQ"
      },
      "source": [
        "#Third Try"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Zn6HAjHpFAB4",
        "outputId": "da7c7f10-3ca4-442e-d048-c1add37eea46"
      },
      "source": [
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "%reload_ext tensorboard\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "#Create Sequential model with Dense layers\n",
        "classifier = Sequential()\n",
        "\n",
        "#hidden layer 1 - input from input data\n",
        "classifier.add(Dense(input_shape=(11,), units=5, kernel_initializer='random_uniform', activation='relu'))\n",
        "\n",
        "#hidden layer 2\n",
        "classifier.add(Dense(units=10, kernel_initializer='random_uniform', activation='relu'))\n",
        "\n",
        "#Binary output layer \n",
        "classifier.add(Dense(units=1, kernel_initializer='random_uniform', activation='sigmoid'))\n",
        "\n",
        "#The compile method configures the model’s learning process\n",
        "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "log_dir = \"logs/thirdTry/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "#The fit method does the training in batches\n",
        "classifier.fit(x_train, y_train, batch_size=20, epochs=100, validation_data=(x_test, y_test), callbacks=[tensorboard_callback])\n",
        "\n",
        "%tensorboard --logdir logs/thirdTry"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mThis cell output is too large and can only be displayed while logged in.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyuY5hFPUYxv"
      },
      "source": [
        "#Forth Try\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rlxrqwjFUXIo",
        "outputId": "25c2e707-1cb0-41b0-f061-71a7a8391c69"
      },
      "source": [
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "%reload_ext tensorboard\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "#Create Sequential model with Dense layers\n",
        "classifier = Sequential()\n",
        "\n",
        "#hidden layer 1 - input from input data\n",
        "classifier.add(Dense(input_shape=(11,), units=11, kernel_initializer='random_uniform', activation='relu'))\n",
        "\n",
        "#hidden layer 2\n",
        "classifier.add(Dense(units=8, kernel_initializer='random_uniform', activation='relu'))\n",
        "\n",
        "#Binary output layer \n",
        "classifier.add(Dense(units=1, kernel_initializer='random_uniform', activation='sigmoid'))\n",
        "\n",
        "#The compile method configures the model’s learning process\n",
        "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "log_dir = \"logs/forthTry/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "#The fit method does the training in batches\n",
        "classifier.fit(x_train, y_train, batch_size=20, epochs=200, validation_data=(x_test, y_test), callbacks=[tensorboard_callback])\n",
        "\n",
        "%tensorboard --logdir logs/forthTry"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mThis cell output is too large and can only be displayed while logged in.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RQL5bNCDDgB"
      },
      "source": [
        "classifier.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fN1ShYq-c_85",
        "outputId": "320e72f9-25c7-4533-c0b1-652f0b8513f2"
      },
      "source": [
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "%reload_ext tensorboard\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "#Create Sequential model with Dense layers\n",
        "classifier = Sequential()\n",
        "\n",
        "#hidden layer 1 - input from input data\n",
        "classifier.add(Dense(input_shape=(11,), units=13, kernel_initializer='random_uniform', activation='relu'))\n",
        "\n",
        "#hidden layer 2\n",
        "classifier.add(Dense(units=8, kernel_initializer='random_uniform', activation='relu'))\n",
        "\n",
        "#Binary output layer \n",
        "classifier.add(Dense(units=1, kernel_initializer='random_uniform', activation='sigmoid'))\n",
        "\n",
        "#The compile method configures the model’s learning process\n",
        "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "log_dir = \"logs/fifthTry/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "#The fit method does the training in batches\n",
        "classifier.fit(x_train, y_train, batch_size=None, epochs=100, validation_data=(x_test, y_test), callbacks=[tensorboard_callback])\n",
        "\n",
        "%tensorboard --logdir logs/fifthTry"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mThis cell output is too large and can only be displayed while logged in.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8V0UCoRrkZS"
      },
      "source": [
        "#Sixth Try"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qCqPNhflfRQj",
        "outputId": "cbdf7692-d7c0-40a1-bd17-d27a68f7eaea"
      },
      "source": [
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "%reload_ext tensorboard\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "#Create Sequential model with Dense layers\n",
        "classifier = Sequential()\n",
        "\n",
        "#hidden layer 1 - input from input data\n",
        "classifier.add(Dense(input_shape=(11,), units=20, kernel_initializer='random_uniform', activation='relu'))\n",
        "\n",
        "#hidden layer 2\n",
        "classifier.add(Dense(units=10, kernel_initializer='random_uniform', activation='relu'))\n",
        "\n",
        "#Binary output layer \n",
        "classifier.add(Dense(units=1, kernel_initializer='random_uniform', activation='sigmoid'))\n",
        "\n",
        "#The compile method configures the model’s learning process\n",
        "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "log_dir = \"logs/sixthTry/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "#The fit method does the training in batches\n",
        "classifier.fit(x_train, y_train, batch_size=10, epochs=100, validation_data=(x_test, y_test), callbacks=[tensorboard_callback])\n",
        "\n",
        "%tensorboard --logdir logs/sixthTry"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mThis cell output is too large and can only be displayed while logged in.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mls2WzCQra47"
      },
      "source": [
        "#Seventh Try"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O3tTgiSUjd7w",
        "outputId": "aa3bb3ea-d0e7-4df3-b6f4-94b7e1e93d7b"
      },
      "source": [
        "import tensorflow as tf\n",
        "import datetime\n",
        "\n",
        "%reload_ext tensorboard\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "#Create Sequential model with Dense layers\n",
        "classifier = Sequential()\n",
        "\n",
        "#hidden layer 1 - input from input data\n",
        "classifier.add(Dense(input_shape=(11,), units=12, kernel_initializer='random_uniform', activation='relu'))\n",
        "\n",
        "#hidden layer 2\n",
        "classifier.add(Dense(units=3, kernel_initializer='random_uniform', activation='relu'))\n",
        "\n",
        "#Binary output layer \n",
        "classifier.add(Dense(units=1, kernel_initializer='random_uniform', activation='sigmoid'))\n",
        "\n",
        "#The compile method configures the model’s learning process\n",
        "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "log_dir = \"logs/seventhTry/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "#The fit method does the training in batches\n",
        "classifier.fit(x_train, y_train, batch_size=None, epochs=100, validation_data=(x_test, y_test), callbacks=[tensorboard_callback])\n",
        "\n",
        "%tensorboard --logdir logs/seventhTry"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mThis cell output is too large and can only be displayed while logged in.\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}
